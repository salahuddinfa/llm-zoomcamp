{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests \n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from decouple import config\n",
    "import tiktoken\n",
    "# from decouple import config\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "# client = OpenAI(\n",
    "#     base_url='http://localhost:11434/v1/',\n",
    "#     api_key='ollama',\n",
    "# )\n",
    "# print(os.environ.get(\"api_key\"))\n",
    "client = OpenAI(\n",
    "    api_key=config(\"api_key\"),\n",
    "    base_url=\"https://api.aimlapi.com\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents():\n",
    "    docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "    # print(documents_raw)\n",
    "    documents = []\n",
    "    \n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "        # print(course_name)\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            documents.append(doc)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_index(index_name='course', documents=None):\n",
    "    index_settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "                \"section\": {\"type\": \"text\"},\n",
    "                \"question\": {\"type\": \"text\"},\n",
    "                \"course\": {\"type\": \"keyword\"} \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if not es.indices.exists(index=index_name):\n",
    "        response = es.indices.create(index=index_name, body=index_settings)\n",
    "    \n",
    "    for doc in tqdm(documents):\n",
    "        es.index(index=index_name, document=doc)\n",
    "    return index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(query, index_name='course', max_results=3):\n",
    "    search_query = {\n",
    "        \"size\": max_results,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es.search(index=index_name, body=search_query)\n",
    "    top_n_matched_questions = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    return top_n_matched_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def build_context(documents):\n",
    "    context_result = \"\"\n",
    "    \n",
    "    for doc in documents:\n",
    "        doc_str = context_template.format(**doc)\n",
    "        context_result += (\"\\n\\n\" + doc_str)\n",
    "    \n",
    "    return context_result.strip()\n",
    "\n",
    "\n",
    "def build_prompt(user_question, documents):\n",
    "    context = build_context(documents)\n",
    "    prompt = prompt_template.format(\n",
    "        question=user_question,\n",
    "        context=context\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def ask_openai(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model='mistralai/Mistral-7B-Instruct-v0.2',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "def qa_bot(user_question):\n",
    "    context_docs = retrieval(user_question)\n",
    "    # print(json.dumps(context_docs, indent=4))\n",
    "    prompt = build_prompt(user_question, context_docs)\n",
    "    print(\"len of prompt\",len(prompt))\n",
    "    print(\"tokens of prompt\", len(encoding.encode(prompt)))\n",
    "    answer = ask_openai(prompt, \"phi3\")\n",
    "    print(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to include the documents in the elastic_search, only after that we can run rest of the processes of prompting\n",
    "def run():\n",
    "    documents = get_documents()\n",
    "    index_name = setup_index(\"courses\", documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:01<00:00, 801.43it/s]\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of prompt 1322\n",
      "tokens of prompt 298\n",
      " To execute a command in a running Docker container, follow these steps:\n",
      "\n",
      "1. Find the container ID using the command `docker ps`.\n",
      "2. Execute the command in the container using the command `docker exec -it <container-id> <command>`. Replace `<container-id>` with the actual container ID and `<command>` with the command you want to execute. In this case, replace `<command>` with `bash` if you want to open a bash shell in the container.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To execute a command in a running Docker container, follow these steps:\\n\\n1. Find the container ID using the command `docker ps`.\\n2. Execute the command in the container using the command `docker exec -it <container-id> <command>`. Replace `<container-id>` with the actual container ID and `<command>` with the command you want to execute. In this case, replace `<command>` with `bash` if you want to open a bash shell in the container.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "qa_bot(\"How do I execute a command in a running docker container?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.7.0-cp39-cp39-macosx_11_0_arm64.whl (907 kB)\n",
      "\u001b[K     |████████████████████████████████| 907 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Downloading regex-2024.5.15-cp39-cp39-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[K     |████████████████████████████████| 278 kB 70.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in ./llm-zoom/lib/python3.9/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./llm-zoom/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./llm-zoom/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./llm-zoom/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./llm-zoom/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.5.15 tiktoken-0.7.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1 is available.\n",
      "You should consider upgrading via the '/Users/salahuddinpalagiri/Desktop/Repos/Mera/llm-zoomcamp/search-implementation/llm-zoom/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
